{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3db585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 自動從 CSV 生成清單（依 custom_score 降序）。\n",
      "共載入 271 個檔名。\n",
      "📚 已載入 593 筆 Bib 條目。\n",
      "✅ 輸出 271 筆 → 按輸入順序.md\n",
      "✅ 輸出 271 筆 → 按筆畫排序.md\n",
      "🎯 所有檔案皆成功匹配。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# === 可調整參數 ===\n",
    "root_dir = Path.cwd()             # bib 檔所在根目錄\n",
    "reference_file = Path(\"reference/Unihan_IRGSources.txt\")\n",
    "output_dir = Path(\"match_bib_output_md\")\n",
    "mode = 3                          # 1=依輸入順序；2=依筆畫；3=兩者都輸出\n",
    "prefix_digits = 3                 # 流水號位數\n",
    "TOP_N = None                       # 只輸出前 N 筆（None 表示全部）\n",
    "CSV_PATH = Path(\"filtered_keywords_with_score.csv\")  # 若無手動貼清單則自動依 CSV\n",
    "\n",
    "# === 手動清單（留空則自動使用 CSV） ===\n",
    "file_names_text = \"\"\" \"\"\"\n",
    "\n",
    "# === 清單來源 ===\n",
    "if file_names_text.strip():\n",
    "    print(\"📄 使用手動貼上的檔名清單。\")\n",
    "    file_names = [x.strip() for x in file_names_text.splitlines() if x.strip()]\n",
    "else:\n",
    "    print(\"📊 自動從 CSV 生成清單（依 custom_score 降序）。\")\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    if \"paper_name\" not in df.columns:\n",
    "        raise ValueError(\"CSV 檔缺少欄位 'paper_name'\")\n",
    "    df_sorted = df.sort_values(\"custom_score\", ascending=False)\n",
    "    if TOP_N is not None:\n",
    "        df_sorted = df_sorted.head(TOP_N)\n",
    "        print(f\"⚙️ 僅輸出前 {TOP_N} 篇（依 custom_score 排序）\")\n",
    "    file_names = list(df_sorted[\"paper_name\"])\n",
    "\n",
    "print(f\"共載入 {len(file_names)} 個檔名。\")\n",
    "\n",
    "# === 載入筆畫表 ===\n",
    "def load_stroke_table(path):\n",
    "    table = {}\n",
    "    if not path.exists():\n",
    "        return table\n",
    "    pattern = re.compile(r\"U\\+([0-9A-F]+)\\s+kTotalStrokes\\s+(\\d+)\")\n",
    "    for line in path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        m = pattern.search(line)\n",
    "        if m:\n",
    "            char = chr(int(m.group(1), 16))\n",
    "            table[char] = int(m.group(2))\n",
    "    return table\n",
    "\n",
    "strokes_table = load_stroke_table(reference_file)\n",
    "\n",
    "# === 正規化 ===\n",
    "def normalize(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"[ \\u3000]\", \" \", s)\n",
    "    s = re.sub(r\"[–—－]\", \"-\", s)\n",
    "    s = re.sub(r\"[：﹕]\", \":\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# === 筆畫數 ===\n",
    "def stroke_count(name: str) -> int:\n",
    "    count = 0\n",
    "    for ch in name:\n",
    "        if ch in strokes_table:\n",
    "            count += strokes_table[ch]\n",
    "        elif unicodedata.category(ch).startswith(\"Lo\"):\n",
    "            count += 10  # 未知字預設10筆畫\n",
    "    return count\n",
    "\n",
    "# === 解析 Bib ===\n",
    "def parse_bib_entry(text):\n",
    "    title_match = re.search(r\"title\\s*=\\s*\\{([^}]+)\\}\", text)\n",
    "    author_match = re.search(r\"author\\s*=\\s*\\{([^}]+)\\}\", text)\n",
    "    how_match = re.search(r\"howpublished\\s*=\\s*\\{([^}]+)\\}\", text)\n",
    "    if title_match:\n",
    "        title = normalize(title_match.group(1))\n",
    "        author = normalize(author_match.group(1)) if author_match else \"\"\n",
    "        how = normalize(how_match.group(1)) if how_match else \"\"\n",
    "        return title, author, how\n",
    "    return None, None, None\n",
    "\n",
    "# === 掃描 Bib ===\n",
    "bib_files = list(root_dir.rglob(\"*.bib\"))\n",
    "entries = []\n",
    "for bib_path in bib_files:\n",
    "    text = bib_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    for raw in re.split(r\"@article|@book|@misc\", text)[1:]:\n",
    "        title, author, how = parse_bib_entry(raw)\n",
    "        if title:\n",
    "            entries.append((title, author, how))\n",
    "print(f\"📚 已載入 {len(entries)} 筆 Bib 條目。\")\n",
    "\n",
    "# === 比對檔名 ===\n",
    "matches = []\n",
    "for fname in file_names:\n",
    "    for title, author, how in entries:\n",
    "        if normalize(title).replace(\" \", \"\") in normalize(fname).replace(\" \", \"\"):\n",
    "            matches.append((fname, title, author, how))\n",
    "            break\n",
    "\n",
    "# === 匯出結果 ===\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def export_markdown(data, filename, title):\n",
    "    lines = [\n",
    "        f\"# {title}\",\n",
    "        \"\",\n",
    "        f\"**生成時間**：{timestamp}\",\n",
    "        \"\",\n",
    "        f\"此檔案列出自動比對所得文獻引用清單（共 {len(data)} 筆）。\",\n",
    "        \"\",\n",
    "        \"以下依指定順序編號：\",\n",
    "        \"\"\n",
    "    ]\n",
    "    for i, (_, _, _, how) in enumerate(data, start=1):\n",
    "        num = f\"{i:0{prefix_digits}d}\"\n",
    "        lines.append(f\"{num}. {how}\")\n",
    "    (output_dir / filename).write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    print(f\"✅ 輸出 {len(data)} 筆 → {filename}\")\n",
    "\n",
    "# === 主輸出 ===\n",
    "if mode in (1, 3):\n",
    "    export_markdown(matches, \"按輸入順序.md\", \"文獻清單（按輸入順序）\")\n",
    "\n",
    "if mode in (2, 3):\n",
    "    sorted_matches = sorted(matches, key=lambda x: stroke_count(x[2]) if x[2] else 0)\n",
    "    export_markdown(sorted_matches, \"按筆畫排序.md\", \"文獻清單（按作者筆畫排序）\")\n",
    "\n",
    "# === 找出未匹配項 ===\n",
    "matched_fnames = {m[0] for m in matches}\n",
    "unmatched = [f for f in file_names if f not in matched_fnames]\n",
    "\n",
    "if unmatched:\n",
    "    miss_path = output_dir / \"未匹配清單.txt\"\n",
    "    miss_path.write_text(\"\\n\".join(unmatched), encoding=\"utf-8\")\n",
    "    print(f\"⚠️ 未匹配 {len(unmatched)} 筆，已輸出 → {miss_path.resolve()}\")\n",
    "else:\n",
    "    print(\"🎯 所有檔案皆成功匹配。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
