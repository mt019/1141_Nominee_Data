# 我的 NLP＋法律資料爬取與分析系統全紀錄

## 一、起點：從爬蟲開始

我整個專案最早不是從 NLP 開始，而是從一個「**針對法律文獻的爬蟲**」出發。  
我先設計了一個自動化爬蟲，用來抓取所有與特定關鍵字（例如「稅捐」、「借名登記」、「信託」、「租稅規避」等）相關的論文與期刊文章。  

### 我當時的邏輯：
1. 用 `requests` + `BeautifulSoup` 模擬查詢；
2. 逆向分析 ASP.NET 站台的 `__VIEWSTATE`、`__EVENTVALIDATION`、`__VIEWSTATEGENERATOR`；
3. 用表單提交模擬使用者行為；
4. 遞迴分頁解析每篇文章連結；
5. 自動下載 PDF，並依標題與作者命名；
6. 建立分類索引（稅法、民法、行政法、信託等主題）。

在這個階段，我處理了：
- **Headers/Cookies 模擬**，避開反爬蟲；
- **隨機延遲**，降低被封風險；
- **錯誤重試與斷點續傳**；
- **自動命名正規化**；
- **排除重複 PDF（依檔名與內容雜湊）**。

最終我建立了數百篇與特定稅法、借名登記主題相關的法律文獻 PDF，  
這是整個系統的資料基礎。

---

## 二、語料化：PDF → JSON

爬完之後，我寫了一個 **PDF 文字解析模組**，用於將 PDF 系統化轉換為可分析的文字資料。

功能：
- 遞迴掃描所有 PDF；
- 使用 `pdfminer.six` 提取純文字；
- 清理頁碼、頁眉頁腳、空白頁；
- 以檔名為 key 建立索引；
- 輸出 `all_pdfs_parsed.json`；
- 若 JSON 已存在，只解析「新增」文件；
- 顯示「新增了哪些」、「跳過了哪些」。

資料結構如下：

```json
{
  "filename": "陳清秀 - 稅法上借牌營業課稅問題之探討.pdf",
  "text": "……",
  "path": "source/pdfs/稅法/",
  "word_count": 14237,
  "keywords_found": ["稅", "借名", "信託"],
  "verdicts": 8
}
```

這讓所有文獻成為「可檢索語料」，而非只是靜態 PDF。

---

## 三、語料分析：關鍵詞篩選與統計

在 `all_pdfs_parsed.json` 基礎上，我建立了一個自動化的關鍵詞篩選與排序系統。  

主要邏輯：
- 檢查每篇文獻中是否出現特定關鍵詞（如「稅」、「借用他人」、「借名」、「信託」）；
- 排除干擾詞（如「草稿」或非實質內容）；
- 統計各詞出現次數；
- 對特定詞組的共現進行加權；
- 輸出包含所有詞頻的 CSV；
- 建立自定義評分指標 `custom_score`。

### Custom Score 設計
```python
rec["custom_score"] = (
    (rec.get("count_稅", 0) + 1)
    * (rec.get("count_借用他人", 0)
       + rec.get("count_借名", 0)
       + rec.get("count_利用他人", 0))
    + sum(v for k, v in rec.items() if k.startswith("count_"))
)
```

此指標能綜合反映一篇文獻與「借名登記 + 稅捐」主題的關聯程度。  
結果輸出為：
```
filtered_keywords_with_score.csv
```
可直接用於排序與後續比對。

---

## 四、語意分析與可視化

我接著進行 NLP 層面的語意分析：
1. 用 `jieba` 做中文斷詞；
2. 去除停用詞；
3. 建立共現矩陣；
4. 計算 PMI（Pointwise Mutual Information）；
5. 輸出共現關係表；
6. 用 `matplotlib` 視覺化詞對關係。

成果包括：
- 關鍵詞共現熱力圖；
- 高頻詞統計圖；
- 詞對網絡圖。

並修正了 matplotlib 中文字體顯示問題（強制使用 PingFang、Heiti、SimHei）。

---

## 五、Bib 引用比對系統

這一步是整個系統的「知識化階段」。

我寫了一個 `.bib` 比對模組：
- 掃描所有 `.bib`；
- 解析 `title`, `author`, `howpublished`；
- 用正則去除空白、標點差異、全形半形差異；
- 與 PDF 檔名比對；
- 若符合 → 輸出匹配清單；
- 若不符 → 輸出「未匹配清單.txt」。

我還使用了 `Unihan_IRGSources.txt` 解析作者筆畫數，
用筆畫排序產生兩種清單：

1. `按輸入順序.md`
2. `按筆畫排序.md`

每份檔案都有：
- 生成時間；
- 流水號；
- 匯出筆數；
- howpublished 引用格式。

---

## 六、整體架構

```
[爬蟲收集 PDF]
        ↓
[PDF → JSON 語料]
        ↓
[關鍵詞統計 + 自定指標排序]
        ↓
[CSV 匯出]
        ↓
[Bib 比對 → Markdown 清單]
        ↓
[語義分析 + 可視化]
```

整個管線從網站 → PDF → 語料 → 結構化知識，全自動化。

---

## 七、技術棧總覽

| 模組 | 技術 |
|------|------|
| 爬蟲 | `requests`, `BeautifulSoup`, ASP.NET 模擬 |
| PDF 解析 | `pdfminer.six` |
| NLP 分析 | `jieba`, `Counter`, `PMI`, `pandas` |
| 可視化 | `matplotlib`（中文字體修正） |
| 統計與篩選 | `pandas`, `collections.Counter` |
| 引用比對 | `re`, `unicodedata`, `json`, `pathlib` |
| 筆畫排序 | `Unihan_IRGSources.txt` |
| 輸出格式 | Markdown + CSV + JSON |

---

## 八、我實現的功能其實是文獻系統該有的功能

原本的法學資料庫（例如 Lawbank、期刊檢索系統）  
雖然可以查詢與下載，但缺乏：
- 智能分類與主題關聯；
- 內文比對；
- 語料統計；
- Bib 引用匹配；
- 可視化分析；
- 結構化輸出。

所以我做的其實是：
> 一個現代文獻系統應該具備，但現有系統沒做到的功能。

我把整個「查找、分析、比對、整理」自動化。  
我讓 PDF 不只是檔案，而是「可以理解的文本物件」。

---

## 九、價值與定位

用產品思維來看，我實際開發的是：
> 一個能理解法律文本、能分析主題關聯、能自動建立引用的智慧文獻系統。

它的功能橫跨：
- 爬蟲工程；
- 文本處理；
- 語料學；
- NLP；
- 引用學；
- 法律資訊學。

若以市場估值來算，這樣的系統在學研或政府智庫環境：
- 開發成本約 **15–25 萬台幣／月**；
- 若作為產品，年化價值可達 **百萬級別**；
- 可直接嵌入內部法學資料庫，節省研究人力。

---

## 十、最終反思與總結

我原本只是想整理文獻。  
但因為現有文獻系統太難用，我最後重寫了一整個「文獻理解引擎」。

我做的不是小工具，而是一個：
> 從資料擷取 → 語料結構化 → 語義分析 → 引用整合 → 可視化 → Markdown 匯出  
的全流程系統。

最簡結論是：

> 我用 NLP 讓法律文獻變得能被理解、能被排序、能被引用。  
>  
> 我做的，不只是資料整理，而是讓「法律研究」變成一個**可計算的學科行為**。