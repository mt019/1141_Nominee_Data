{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b923d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始篇數：37\n",
      "重複篇數：4\n",
      "\n",
      "重複條目：\n",
      " - 稅捐稽徵協力義務、推計課稅與協力義務違反的制裁－以納稅者權利保護法第 14 條規定討論與條文修正建議為中心 / 柯格鐘 / 2019\n",
      " - 論菸稅與菸品健康福利捐之財政民主統制 / 廖欽福 / 2016\n",
      " - 實質課稅與稅捐規避行為之舉證責任 / 黃源浩 / 2014\n",
      " - 實質課稅原則之適用界限 / 陳清秀 / 2011\n",
      "\n",
      "去重後篇數：33\n",
      "去重後條目：\n",
      " - 稅捐假扣押制度之裁判分析（中） / 黃俊杰 / 2025\n",
      " - 跨國稅捐事務的思考流程與審查步驟 / 陳衍任 / 2024\n",
      " - 稅法上借牌營業課稅問題之探討－從體系正義觀點出發 / 陳清秀 / 2024\n",
      " - 再論租稅刑罰與租稅行政罰之關係 / 柯格鐘 / 2022\n",
      " - 租稅核課處分存續力之突破與退稅請求權 / 盛子龍 / 2022\n",
      " - 納保法實施後稅務專庭對於納稅者權利保障的實踐 / 謝如蘭 / 2022\n",
      " - 夫妻財產制之法理探析－兼論稅務及土地實務運作 / 羅裕翔 and 趙逸凡 / 2021\n",
      " - 打房的第二支箭－評析支持囤房稅正反雙方論點 / 趙逸凡 / 2021\n",
      " - 借用他人名義在特銷稅上的評價－最高行政法院 109 年度上字第 5886 號判決簡評 / 柯格鐘 / 2021\n",
      " - 臺灣傳奇「青果大王」欠稅案 / 盧秀虹 / 2021\n",
      " - 租稅協定之解釋適用（下） / 陳清秀 / 2021\n",
      " - 租稅協定之適用問題－以臺英租稅協定之適用為例 / 陳清秀 / 2020\n",
      " - 事實認定錯誤之溢繳稅款的返還－最高行政法院 107 年度判字第 340 號判決評釋 / 柯格鐘 / 2020\n",
      " - 稅捐稽徵協力義務、推計課稅與協力義務違反的制裁－以納稅者權利保護法第 14 條規定討論與條文修正建議為中心 / 柯格鐘 / 2019\n",
      " - 營業稅法信託課稅問題之研討－以德國法為比較中心（下） / 江彥佐 / 2018\n",
      " - 營業稅法信託課稅問題之研討－以德國法為比較中心（上） / 江彥佐 / 2018\n",
      " - 從私法自治權之保障，談稅法對於私法秩序之融合原則 / 陳清秀 / 2017\n",
      " - 論菸稅與菸品健康福利捐之財政民主統制 / 廖欽福 / 2016\n",
      " - 稅法上之正當法律程序 / 陳清秀 / 2016\n",
      " - 論欠稅限制出境之合憲性 / 范文清 / 2015\n",
      " - 實質課稅與稅捐規避行為之舉證責任 / 黃源浩 / 2014\n",
      " - 論稅捐規避行為之立法與行為的類型化 / 柯格鐘 / 2014\n",
      " - 行政法院歷年來優良稅法判決評析 / 陳清秀 / 2013\n",
      " - 不動產稅制改革芻議－下 / 柯格鐘 / 2013\n",
      " - 實質課稅原則之適用界限 / 陳清秀 / 2013\n",
      " - 股票孳息他益信託之課稅－從信託法理談起 / 柯格鐘 / 2013\n",
      " - 營業稅之稅捐主體與客體之探討 / 陳清秀 / 2013\n",
      " - 稅務行政爭訟舉證責任相關問題探討 / 陳清秀 / 2012\n",
      " - 稅法實務導讀（最高行政法院 100 年度判字第 336 號判決等 5 則裁判之說明） / 陳清秀 / 2011\n",
      " - 稅務行政訴訟若干舉證問題析論－以台北高等行政法院 97 年度訴字第 1792 號判決為例案 / 李建良 / 2011\n",
      " - 稅捐規避及其相關聯概念之辨正 / 柯格鐘 / 2009\n",
      " - 從實質課稅原則論贈與不法所得之課稅問題 / 王志誠 and 葛冠琳 / 2009\n",
      " - 實質課稅原則裁判之研討 / 陳清秀 / 2008\n",
      "\n",
      "✅ 已輸出去重後檔案：lawbank_runs/稅_借名_借用/papers_dedup.bib\n",
      "\n",
      "✅ 已輸出 howpublish DOCX（共 33 筆）：【稅_借名】文獻清單匯出.docx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "\n",
    "# === 使用者設定 ===\n",
    "INPUT_BIB_PATH = Path('lawbank_runs/稅_借名_借用/papers.bib')\n",
    "DEDUP_BIB_PATH = Path('lawbank_runs/稅_借名_借用/papers_dedup.bib')\n",
    "HOWPUBLISH_DOCX_PATH = Path('【稅_借名】文獻清單匯出.docx')\n",
    "HOWPUBLISH_SORT_MODE = 'stroke'  # 'stroke' 或 'date'\n",
    "DATE_SORT_DESCENDING = True      # 僅在 HOWPUBLISH_SORT_MODE='date' 時生效\n",
    "STROKE_DATA_PATH = Path('reference/Unihan_IRGSources.txt')\n",
    "\n",
    "# === 工具函式 ===\n",
    "def clean_entry(entry: str) -> str:\n",
    "    \"\"\"刪除值為『未知』『無』或空 {} 的欄位\"\"\"\n",
    "    return re.sub(\n",
    "        r'^\\s*\\w+\\s*=\\s*\\{\\s*(?:未知|無)?\\s*\\},?,?\\s*$',\n",
    "        '',\n",
    "        entry,\n",
    "        flags=re.MULTILINE\n",
    "    )\n",
    "\n",
    "def parse_entry(entry: str):\n",
    "    \"\"\"解析 Bib 條目\"\"\"\n",
    "    m_type = re.match(r'(\\w+)\\s*\\{', entry)\n",
    "    m_title = re.search(r'title\\s*=\\s*\\{(.*?)\\}', entry, re.DOTALL)\n",
    "    m_author = re.search(r'author\\s*=\\s*\\{(.*?)\\}', entry, re.DOTALL)\n",
    "    m_year = re.search(r'year\\s*=\\s*\\{(.*?)\\}', entry)\n",
    "    typ = m_type.group(1) if m_type else 'unknown'\n",
    "    title = m_title.group(1).strip() if m_title else '未知標題'\n",
    "    author = m_author.group(1).strip() if m_author else '未知作者'\n",
    "    year = m_year.group(1).strip() if m_year else '未知年份'\n",
    "    cleaned_entry = clean_entry(entry)\n",
    "    return typ, title, author, year, cleaned_entry\n",
    "\n",
    "def extract_field(entry: str, field_name: str):\n",
    "    pattern = rf'{field_name}\\s*=\\s*\\{{(.*?)\\}}'\n",
    "    match = re.search(pattern, entry, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        value = match.group(1).strip()\n",
    "        return value or None\n",
    "    return None\n",
    "\n",
    "def parse_date_from_text(text: str) -> datetime:\n",
    "    match = re.search(r'(\\d{4})年\\s*(\\d{1,2})?月?\\s*(\\d{1,2})?日?', text)\n",
    "    if not match:\n",
    "        return datetime.min\n",
    "    year = int(match.group(1))\n",
    "    month = int(match.group(2)) if match.group(2) else 1\n",
    "    day = int(match.group(3)) if match.group(3) else 1\n",
    "    try:\n",
    "        return datetime(year, month, day)\n",
    "    except ValueError:\n",
    "        return datetime(year, month, 1)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def load_stroke_map():\n",
    "    stroke_map = {}\n",
    "    path = STROKE_DATA_PATH\n",
    "    if not path.exists():\n",
    "        print(f'⚠️ 找不到字根筆畫檔案：{path}，將以字典順序排序作者。')\n",
    "        return stroke_map\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if '\\tkTotalStrokes\\t' not in line:\n",
    "                continue\n",
    "            code, field, value = line.strip().split('\\t')\n",
    "            if field != 'kTotalStrokes':\n",
    "                continue\n",
    "            primary = value.split()[0]\n",
    "            try:\n",
    "                cp = int(code[2:], 16)\n",
    "                stroke_map[chr(cp)] = int(primary)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return stroke_map\n",
    "\n",
    "def stroke_key(name: str):\n",
    "    stroke_map = load_stroke_map()\n",
    "    if not stroke_map:\n",
    "        return (name,)\n",
    "    counts = []\n",
    "    for ch in name:\n",
    "        if ch.isspace():\n",
    "            continue\n",
    "        counts.append(stroke_map.get(ch, 100))\n",
    "    return tuple(counts) if counts else (100,)\n",
    "\n",
    "def parse_howpublish_entry(text: str):\n",
    "    author_segment, _, _ = text.partition('，')\n",
    "    primary_author = author_segment.split('、')[0].strip() if author_segment else '未知作者'\n",
    "    date_value = parse_date_from_text(text)\n",
    "    return {\n",
    "        'raw': text,\n",
    "        'primary_author': primary_author,\n",
    "        'date': date_value,\n",
    "    }\n",
    "\n",
    "def collect_howpublish(entries):\n",
    "    values = []\n",
    "    for _, _, _, entry in entries:\n",
    "        howpublish = extract_field(entry, 'howpublished') or extract_field(entry, 'howpublish')\n",
    "        if howpublish:\n",
    "            values.append(parse_howpublish_entry(howpublish))\n",
    "    return values\n",
    "\n",
    "def sort_howpublish(entries):\n",
    "    mode = HOWPUBLISH_SORT_MODE.lower()\n",
    "    if mode == 'date':\n",
    "        return sorted(\n",
    "            entries,\n",
    "            key=lambda item: (item['date'], stroke_key(item['primary_author']), item['raw']),\n",
    "            reverse=DATE_SORT_DESCENDING\n",
    "        )\n",
    "    return sorted(\n",
    "        entries,\n",
    "        key=lambda item: (stroke_key(item['primary_author']), item['date'], item['raw'])\n",
    "    )\n",
    "\n",
    "def write_howpublish_docx(items, output_path: Path):\n",
    "    if not items:\n",
    "        print()\n",
    "        print('⚠️ 去重後條目未找到 howpublish 欄位，未產生 DOCX。')\n",
    "        return\n",
    "    md_path = output_path.with_suffix('.md')\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    sorted_items = sort_howpublish(items)\n",
    "    sort_label = '作者筆畫' if HOWPUBLISH_SORT_MODE.lower() == 'stroke' else '出版時間'\n",
    "    total_count = len(sorted_items)\n",
    "    lines = [\n",
    "        '# 文獻清單 匯出',\n",
    "        f'- 產出時間：{timestamp}',\n",
    "        f'- 排序方式：{sort_label}',\n",
    "        f'- 條目總數：{total_count}',\n",
    "        '',\n",
    "        '## 條目清單',\n",
    "        ''\n",
    "    ] + [f\"{idx_val}. {item['raw']}\" for idx_val, item in enumerate(sorted_items, 1)]\n",
    "\n",
    "    md_path.write_text('\\n'.join(lines), encoding='utf-8')\n",
    "\n",
    "    subprocess.run([\n",
    "        'pandoc',\n",
    "        str(md_path),\n",
    "        '-f', 'markdown',\n",
    "        '-t', 'docx',\n",
    "        '-o', str(output_path)\n",
    "    ], check=True)\n",
    "\n",
    "    print()\n",
    "    print(f\"✅ 已輸出 howpublish DOCX（共 {len(sorted_items)} 筆）：{output_path}\")\n",
    "\n",
    "# === 主流程 ===\n",
    "text = INPUT_BIB_PATH.read_text(encoding='utf-8')\n",
    "entries = re.split(r'@(?=\\w+\\s*\\{)', text)\n",
    "entries = [e.strip() for e in entries if e.strip()]\n",
    "parsed = [parse_entry(e) for e in entries]\n",
    "\n",
    "# === 去重 ===\n",
    "seen = {}\n",
    "duplicates = []\n",
    "for typ, title, author, year, entry in parsed:\n",
    "    key = title.lower()\n",
    "    if key in seen:\n",
    "        duplicates.append((title, author, year))\n",
    "    else:\n",
    "        seen[key] = (title, author, year, entry)\n",
    "unique_entries = list(seen.values())\n",
    "\n",
    "# === 統計輸出 ===\n",
    "total_count = len(parsed)\n",
    "dup_count = len(duplicates)\n",
    "unique_count = len(unique_entries)\n",
    "print(f'原始篇數：{total_count}')\n",
    "print(f'重複篇數：{dup_count}')\n",
    "if dup_count:\n",
    "    print()\n",
    "    print('重複條目：')\n",
    "    for title, author, year in duplicates:\n",
    "        print(f' - {title} / {author} / {year}')\n",
    "print()\n",
    "print(f'去重後篇數：{unique_count}')\n",
    "print('去重後條目：')\n",
    "for title, author, year, _ in unique_entries:\n",
    "    print(f' - {title} / {author} / {year}')\n",
    "\n",
    "# === 寫出去重後 Bib ===\n",
    "dedup_text = '\\n\\n'.join(f\"@{entry}\" for _, _, _, entry in unique_entries)\n",
    "DEDUP_BIB_PATH.write_text(dedup_text, encoding='utf-8')\n",
    "print()\n",
    "print(f\"✅ 已輸出去重後檔案：{DEDUP_BIB_PATH}\")\n",
    "\n",
    "# === 匯出 howpublish DOCX ===\n",
    "howpublish_items = collect_howpublish(unique_entries)\n",
    "write_howpublish_docx(howpublish_items, HOWPUBLISH_DOCX_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e109fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
